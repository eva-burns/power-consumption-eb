---
title: "Power Consumption Exploration and Forecasting"
author: "Eva Burns"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi=300)
```

## Problem Statement

A power consumption study in 2017 was done at Tétouan, Morocco by the Supervisory Control and Data Acquisition System (SCADA) of Amendis, who is in charge of the distribution of drinking water and electricity. Energy consumption is very important to the country, so the purpose of this project is to study and forecast power consumption in Tétouan. The energy distribution network is powered by 3 Zone stations: Quads, Smir and Boussafou. In this project, I will only focus on forecasting Zone 1's (Quads) power consumption. I will be forecasting the last 20 days of December, 2017 starting on 12/11/2017

The data was found from kaggle: [Electric Power Consumption](https://www.kaggle.com/datasets/fedesoriano/electric-power-consumption)

## Assumptions/Hypotheses about Data and Modeling

The data was collected every ten minutes for exactly one year (1/1/2017 0:00 - 12/30/2017 23:50) with nine columns:

- `Datetime`: Time window of ten minutes.
- `Temperature`: Weather Temperature.
- `Humidity`: Weather Humidity.
- `WindSpeed`: Wind Speed.
- `GeneralDiffuseFlows`: “Diffuse flow” is a catchall term to describe low-temperature (< 0.2° to ~ 100°C) fluids that slowly discharge through sulfide mounds, fractured lava flows, and assemblages of bacterial mats and macrofauna.
- `Diffuse Flows`
- **`PowerConsumption_Zone1`**: This is what will be forecasted
- `PowerConsumption_Zone2`
- `PowerConsumption_Zone3`

```{r libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(forecast)
library(xts)
library(TSA)
library(tidyquant)
library(tseries)
library(lmtest)
library(car)
library(reshape2)
```

```{r import}
power <- read.csv("data/powerconsumption.csv")
idx <- which(power$Datetime %in% c('12/11/2017 0:00'))

power$Datetime <- as.POSIXct(power$Datetime, format = "%m/%d/%Y %H:%M")
head(power, 3)

train <- power[1:(idx - 1),]
test <- power[idx:nrow(power),]

train_ts <- ts(train$PowerConsumption_Zone1)
```

Some assumptions about the data collected is that the data was collected when it is said to be collected. That is, it was collected every ten minutes a day. Also, that the sensors were calibrated correctly throughout the year.

I hypothesize that a model with a seasonal component will be most appropriate. I believe there might be two seasonalities: daily and yearly. Throughout the day, power consumption changes. For example, when you are sleeping, power consumption is lower because you are not using appliances or lights around your house. I also think power consumption changes yearly as weather changes during the seasons, affecting AC/heating consumption. However, since this data only covers one year, yearly seasonality will not be able to be used.

## Data properties

```{r properties-1}
hist(train$PowerConsumption_Zone1, main = "Histogram of Power Consumption (Zone 1)", xlab = "PowerConsumption_Zone1")
```

The distribution of the power consumption in Zone 1 does not seem to be normally distributed, but it looks to be somewhat symmetrical.

```{r properties-2, warning=FALSE}
acf(ts(train$PowerConsumption_Zone1), xlab = "lag #", ylab = 'ACF',main=' ')
adf.test(ts(train$PowerConsumption_Zone1))
kpss.test(ts(train$PowerConsumption_Zone1))
```
While the Augmented Dickey-Fuller test gives a low p-value (0.01), concluding that the data is stationary, the ACF plot and KPSS indicate the data is non-stationary since the KPSS p-value is 0.01 (non-stationary) and the ACF plot does not die down quickly.

```{r properties-3}
durbinWatsonTest(train$PowerConsumption_Zone1)
```

The Durbin-Watson test indicates that the power consumption in Zone 1 is positively autocorrelated because the test statistic is close to 0.

## Exploratory Data Analysis

Below is the time series plot of the power consumption in Zone 1 for 2017.
```{r eda}
plot(power$Datetime,power$PowerConsumption_Zone1, type='l', xlab="Month", ylab = "Power Consumption (Zone 1)")
```

Here is the plot zoomed in on what will be forecasted. It seems that there is daily seasonality. This will be confirmed later. 

```{r eda-2}
plot(test$Datetime,test$PowerConsumption_Zone1, type='l', xlab="Date", ylab = "Power Consumption (Zone 1)")
```

Let's look at how the other features of this dataset correlate to the power consumption in Zone 1.

```{r eda-3}
cormat <- round(cor(power[c('PowerConsumption_Zone1', 'Temperature', 'Humidity', 'WindSpeed', 'GeneralDiffuseFlows', 'DiffuseFlows', 'PowerConsumption_Zone2', 'PowerConsumption_Zone3')]),2)

# Melt the correlation matrix
melted_cormat <- melt(cormat, na.rm = TRUE)
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Pearson\nCorrelation") +
  theme_minimal()+ # minimal theme
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed()

ggheatmap + 
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(1.35, 0.1),
  legend.direction = "vertical")+
  guides(fill = guide_colorbar(barwidth = 1, barheight = 7,
                title.position = "top", title.hjust = 0.5))
```

The power consumption in Zones 2 and 3 are the most correlated with power consumption in Zones 1. This makes sense because they are measuring the same thing in a area close to each other. They are visualized below.

```{r eda-4}
plot(power$Datetime,power$PowerConsumption_Zone2, type='l', xlab="Month", ylab = "Power Consumption (Zone 2)")
plot(power$Datetime,power$PowerConsumption_Zone3, type='l', xlab="Month", ylab = "Power Consumption (Zone 3)")
```

## Data processing

Outliers/Anomalies were checked using `tsoutliers`. 

```{r anomaly}
tsoutliers(train$PowerConsumption_Zone1)
```

There were no outliers found, so no data needs to be removed or replaced. 

```{r NA}
sum(is.na(power$PowerConsumption_Zone1))
```

The data is full and collected at regular intervals with no null values, so no cleaning or transformations are required.

## Feature Engineering

Since I suspect that there is a seasonal component to the data, I will apply a frequency periodogram to `PowerConsumption_Zone1` to determine if/what the seasonal period is.

```{r frequency}
p <- periodogram(train_ts)
```

The periodogram indicates that there seems to be a seasonal component to the data. I will calculate the period of seasonality.

```{r frequency-2}
max_freq <- p$freq[which.max(p$spec)]
seasonality <- 1/max_freq
seasonality
```

The periodogram says the seasonality with the highest frequency is `r seasonality`. This indicates there is daily seasonality because the data is collected in 10 minute increments. There are 1440 minutes in a day, which divided by 10 minutes is 144.

## Proposed Approaches

For this project, I will try two different models: TBATS and SARIMA. I will discuss how I chose these two models.

The main feature I wanted to include in a model to forecast the power consumption is seasonality, so I gravitated towards TBATS and SARIMA. TBATS has a lot of features that are spelled out in the name:

**T**rigonometric regressors to model multiple-seasonalities

**B**ox-Cox transformations

**A**RMA errors

**T**rend

**S**easonality

However, because it is a more complex model, there is risk of overfitting the train data, as well as the model itself being computationally expensive.

SARIMA also handles seasonality, but is a simpler model. This will make the time to create the model faster, and may help with overfitting.

I decided not to include dynamic regression (i.e. using any independent variables to predict power consumption) because the variables that are most correlated with power consumption (Zone 1) are the power consumptions of the other zones. Using those other zones does not make sense for the business case of forecasting power consumption because these models could also be used to forecast power consumption in zones 1 and 2.

### TBATS

I will first build the TBATS model using the train data (1/1/2017 00:00 - 12/10/2017 23:50) with a seasonal period of 144.

```{r tbats-build, warning=FALSE}
if (file.exists("tbats.rds")) {
  tbats_model <- readRDS("tbats.rds")
} else {
  # build model if not done already
  tbats_model <- tbats(train_ts, seasonal.periods = c(144))
  saveRDS(tbats_model, "tbats.rds")
}

tbats_model

comp <- tbats.components(tbats_model)
plot(comp)
```

### SARIMA

I will now build the SARIMA model using the train data (1/1/2017 00:00 - 12/10/2017 23:50) using `auto.arima` with a seasonal frequency of 144.

```{r sarima-build, warning=FALSE}
train_ts <- ts(train$PowerConsumption_Zone1, frequency = 144)

if (file.exists("sarima.rds")) {
  sarima_model <- readRDS("sarima.rds")
} else {
  # build model if not done already
  sarima_model <- auto.arima(train_ts)
  saveRDS(sarima_model, "sarima.rds")
}

sarima_model
```
## Results and Learnings

### TBATS

Using the built TBATS model, I will forecast Zone 1's power consumption from 12/11/2017 00:00 - 12/31/2017 23:50. This forecast is visualized below.

```{r tbats-eval, warning=FALSE}
fc_tbats <- forecast(tbats_model, h=nrow(test))

tbat_plot_1 <- power %>%
  ggplot(aes(x = Datetime, y = PowerConsumption_Zone1, color='Actual')) +
  ggtitle("TBATS Forecasted Power Consumption (Zone 1)") + 
  geom_line() +
  geom_line(data = test, mapping = 
              aes(x = Datetime, y = fc_tbats$mean, color="Predicted")) +
  scale_color_manual(name = "Data",
  values = c( "Actual" = "black", "Predicted" = "red"),
  labels = c("Actual", "Predicted")) + 
  coord_x_datetime(xlim = c("2017-10-01 00:00:00", "2017-12-30 23:50:00"))

tbat_plot_2 <- test %>%
  ggplot(aes(x = Datetime, y = PowerConsumption_Zone1, color='Actual')) +
  ggtitle("TBATS Forecasted Power Consumption (Zone 1) Zoomed In") + 
  geom_line() +
  geom_line(data = test, mapping = 
              aes(x = Datetime, y = fc_tbats$mean, color="Predicted")) +
  scale_color_manual(name = "Data",
  values = c( "Actual" = "black", "Predicted" = "red"),
  labels = c("Actual", "Predicted"))

tbat_plot_1
tbat_plot_2
```
The accuracy of the model is evaluated using ME, RMSE, MAE, MPE, MAPE, and MASE.

```{r tbats-eval-2}
acc <- data.frame(accuracy(fc_tbats, test$PowerConsumption_Zone1)[2,1:5])
accuracy(fc_tbats, test$PowerConsumption_Zone1)
```

### SARIMA

Using the built SARIMA model, I will forecast Zone 1's power consumption from 12/11/2017 00:00 - 12/31/2017 23:50. This forecast is visualized below.

```{r sarima-eval, warning=FALSE}
fc_sarima <- forecast(sarima_model, h=nrow(test))

sarima_plot_1 <- power %>%
  ggplot(aes(x = Datetime, y = PowerConsumption_Zone1, color='Actual')) +
  ggtitle("SARIMA Forecasted Power Consumption (Zone 1)") + 
  geom_line() +
  geom_line(data = test, mapping = 
              aes(x = Datetime, y = fc_sarima$mean, color="Predicted")) +
  scale_color_manual(name = "Data",
  values = c( "Actual" = "black", "Predicted" = "red"),
  labels = c("Actual", "Predicted")) + 
  coord_x_datetime(xlim = c("2017-10-01 00:00:00", "2017-12-30 23:50:00"))

sarima_plot_2 <- test %>%
  ggplot(aes(x = Datetime, y = PowerConsumption_Zone1, color='Actual')) +
  ggtitle("SARIMA Forecasted Power Consumption (Zone 1) Zoomed In") + 
  geom_line() +
  geom_line(data = test, mapping = 
              aes(x = Datetime, y = fc_sarima$mean, color="Predicted")) +
  scale_color_manual(name = "Data",
  values = c( "Actual" = "black", "Predicted" = "red"),
  labels = c("Actual", "Predicted"))

sarima_plot_1
sarima_plot_2
```

The accuracy of the model is evaluated using ME, RMSE, MAE, MPE, MAPE, and MASE.

```{r sarima-eval-2}
acc[2] <- accuracy(fc_sarima, test$PowerConsumption_Zone1)[2,1:5]
accuracy(fc_sarima, test$PowerConsumption_Zone1)
```

### Comparison

```{r compare}
colnames(acc) <- c("TBATS", "SARIMA")
acc <- t(acc)
acc
```

TBATS performed better that SARIMA on all accuracy metrics for the train set (as in all metrics were closer to zero). For example the RMSE of TBATS was `r round(acc[1,2], 4)` compared to the RMSE of SARIMA which was `r round(acc[2,2], 4)`. It should be noted, though, that the accuracy of the training data on both models were about equal. This tells us that the SARIMA model is actually the one that overfit the training data.

## Future Work

While the TBATS model performed better to forecast the last two weeks of December, the current dataset ignores one of the main capabilities of the TBATS model: multiple seasonality. As stated earlier, I believe there is yearly seasonality to this data because of how weather changes throughout the year. However, this data is only for 2017, so yearly seasonality cannot be used on this project. If more data from multiple years were used, the TBATS model could be even more accurate than the others because it can handle both daily seasonality as well as the suspected yearly seasonality.

In other words, in the future I believe that collecting more data for multiple years will yield an even more accurate TBATS model because it can be built on multiple seasonalities: daily and yearly.
